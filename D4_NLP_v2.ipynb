{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkBu150HSMO2"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCB_w3d9SMO-"
      },
      "source": [
        "# Text Analytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDlZx66nSMPA"
      },
      "source": [
        "After going through these materials, you will be able to use spaCy or other libraries for:\n",
        "\n",
        "- execution of selected NLP use cases,\n",
        "- preprocessing of unstructured texts,\n",
        "- transformation of preprocessed texts into their structured vector representation.\n",
        "\n",
        "First we import the spaCy library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCde7G3TSMPB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd4IxlmxSMPC",
        "outputId": "ab7fe99d-1986-4fac-dacf-35a10880dbe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2022.5.18.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec\n",
        "\n",
        "word embedding and semantic similarity"
      ],
      "metadata": {
        "id": "XSx5I0pMymP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec \n",
        "import gensim.downloader as api\n",
        "v2w_model = v2w_model = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "adCHIpkiUeIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "King_word2vec_embedding=v2w_model['king']\n",
        "King_word2vec_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjzz6iJpmujP",
        "outputId": "5aaf490a-ea66-4e89-9112-3e2d045c4a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
              "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
              "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
              "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
              "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
              "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
              "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
              "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
              "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
              "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
              "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
              "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
              "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
              "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
              "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
              "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
              "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
              "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
              "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
              "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
              "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
              "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
              "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
              "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
              "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
              "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
              "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
              "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
              "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
              "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
              "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
              "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
              "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
              "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
              "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
              "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
              "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
              "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
              "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
              "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
              "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
              "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
              "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
              "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
              "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
              "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
              "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
              "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
              "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
              "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
              "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
              "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
              "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
              "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
              "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
              "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
              "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
              "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
              "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
              "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
              "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
              "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
              "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
              "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
              "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
              "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
              "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
              "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
              "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
              "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
              "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
              "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
              "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
              "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
              "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "\n",
        "queen_word2vec_embedding=v2w_model['queen']\n",
        "cosine_similarity(King_word2vec_embedding.reshape(1,-1),queen_word2vec_embedding.reshape(1,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nOARLBszL3u",
        "outputId": "7d9e3d85-e263-496b-be39-df01c1c40959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6510957]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "man_word2vec_embedding=v2w_model['man']\n",
        "cosine_similarity(King_word2vec_embedding.reshape(1,-1),man_word2vec_embedding.reshape(1,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efz_KLyB0S1r",
        "outputId": "0afe267f-f771-4813-e4a6-e6a2952b41f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22942673]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "woman_word2vec_embedding=v2w_model['woman']\n",
        "cosine_similarity(King_word2vec_embedding.reshape(1,-1),woman_word2vec_embedding.reshape(1,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7I1Scym0YQp",
        "outputId": "d93b1d59-ddc0-4ceb-9aac-a0968a277183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12847973]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How close is King-Man+Woman is to Queen?"
      ],
      "metadata": {
        "id": "mb9ASwaW03u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_word2vec_embedding=v2w_model['king']-v2w_model['man']+v2w_model['woman']\n",
        "cosine_similarity(x_word2vec_embedding.reshape(1,-1),queen_word2vec_embedding.reshape(1,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYVTPUXj0iIG",
        "outputId": "f38255c0-ab21-4603-b103-d858555794b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7300518]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoToDhC5SMPF"
      },
      "source": [
        "## spaCy language model\n",
        "\n",
        "The Spacy library is built on trained language models. The language model is the result of training on an annotated corpus of documents in a certain language. \n",
        "\n",
        "Language models differ:\n",
        "- the range of data on which they were trained,\n",
        "- layers/methods that can be used when loading a document.\n",
        "\n",
        "### Load  the model\n",
        "The pre-trained language model is loaded after the library is imported with the load command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-sv8b6bSMPG",
        "outputId": "0b0bfea5-5c9d-4e3e-bcb5-94de492824d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<spacy.lang.en.English object at 0x7f3f13e2dd90>\n"
          ]
        }
      ],
      "source": [
        "#nlp = spacy.load(\"en_core_web_sm\")\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load()\n",
        "print(nlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKakl6MCSMPH"
      },
      "source": [
        "### Language Processing Pipelines\n",
        "The basic building block of the language model is *Language Processing Pipeline*, that defines the steps applied to unstructured texts within the processing. Default trained pipeline typically include following steps:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q72k-I9jSMPJ"
      },
      "source": [
        "Each pipeline component returns the processed Doc, which is then\n",
        "passed on to the next component. Spacy pipeline can be modified and additional steps added to it (see section Language detection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muU8sMwzSMPJ",
        "outputId": "576d80b7-309c-4cab-ab9b-480893a17f18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger', 'parser', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amwnc3FrSMPK"
      },
      "source": [
        "## Text preprocessing and feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10tKvt-MSMPL"
      },
      "source": [
        "Example of using:\n",
        "- spaCy for text preprocessing,\n",
        "- models for feature extraction.\n",
        "\n",
        "The obtained structured vector representations of the original unstructured documents have the following properties:\n",
        "\n",
        "- appropriately represent the contents of the original unstructured text documents,\n",
        "- are suitable for analysis or to drive machine learning (ML) algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrc9SuWQSMPL"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import Binarizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ7rrc1GSMPM"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS5tJYkoSMPM"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(unstructured_text):\n",
        "    print(unstructured_text)\n",
        "    \n",
        "    unstructured_text = nlp(unstructured_text)\n",
        "    \n",
        "    # lemmatization of significant tokens of text\n",
        "    lemmatized_tokenized_text = [token.lemma_ for token in unstructured_text\n",
        "                                 if not token.is_punct | token.is_space | token.is_stop == True]\n",
        "    print(lemmatized_tokenized_text)\n",
        "    \n",
        "    # joining tokens into stream\n",
        "    processed_text = ' '.join(lemmatized_tokenized_text)\n",
        "    print(processed_text)\n",
        "\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zw5ulq_SMPN"
      },
      "source": [
        "Extraction of features/terms from unstructured reviews:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "nEhR_0bXSMPN",
        "outputId": "805c99d5-0d77-4b49-daa8-b6f1a947665e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This movie is very scarier and long\n",
            "['movie', 'scary', 'long']\n",
            "movie scary long\n",
            "This movie is not scary and is slow\n",
            "['movie', 'scary', 'slow']\n",
            "movie scary slow\n",
            "This movie is spooky and good and good\n",
            "['movie', 'spooky', 'good', 'good']\n",
            "movie spooky good good\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movie scary long', 'movie scary slow', 'movie spooky good good']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "rewiews = ['This movie is very scarier and long', \n",
        "           'This movie is not scary and is slow', \n",
        "           'This movie is spooky and good and good']\n",
        "\n",
        "preprocessed_rewiews = [preprocess_text(r) for r in rewiews]\n",
        "preprocessed_rewiews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dARhsP1USMPN"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9mvxaNNSMPO"
      },
      "source": [
        "We want to represent each text document with a fixed structured numeric vector. The procedure of feature extraction depends on the selected model:\n",
        "\n",
        "- Binary vectorizer\n",
        "- Bag of Words (BoW) Model\n",
        "- Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "- pre-trained model BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMMv-_bgSMPO"
      },
      "source": [
        "### Binary vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vs2p37bSMPO"
      },
      "source": [
        "The weight in the vector of the given document expresses the fact whether the given term from the dictionary appears in the list of terms of the given document or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEYx_W6eSMPP",
        "outputId": "e09fb025-2f5c-4644-b798-6c7fc93db278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'long', 'movie', 'scary', 'slow', 'spooky']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 2)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 1)\t1\n",
            "  (1, 2)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 4)\t1\n",
            "  (2, 2)\t1\n",
            "  (2, 5)\t1\n",
            "  (2, 0)\t1\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ],
      "source": [
        "bv = CountVectorizer(binary = True)\n",
        "features = bv.fit_transform(preprocessed_rewiews)\n",
        "\n",
        "# print vocabulary\n",
        "bv.get_feature_names()\n",
        "print(features)\n",
        "print(type(features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHaKdIooSMPP"
      },
      "source": [
        "Occurrences of features/terms from vocabulary in the list of features/terms of the given document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-ZrE5K0SMPQ",
        "outputId": "c635cb4f-6412-4967-f519-2d3a1168d2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 0, 'long': 1, 'movie': 1, 'scary': 1, 'slow': 0, 'spooky': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 0, 'long': 0, 'movie': 1, 'scary': 1, 'slow': 1, 'spooky': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 1, 'long': 0, 'movie': 1, 'scary': 0, 'slow': 0, 'spooky': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dict(zip(bv.get_feature_names(), features.toarray()[0]))\n",
        "dict(zip(bv.get_feature_names(), features.toarray()[1]))\n",
        "dict(zip(bv.get_feature_names(), features.toarray()[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQE4cI1VSMPQ"
      },
      "source": [
        "Structured vector representation of three documents in the feature matrix. This matrix can already be folded as in the input to DM/ML algorithms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLWAm6hESMPQ",
        "outputId": "dcbb68fd-8594-4b05-bfd8-17cc83b1a6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0],\n",
              "       [0, 0, 1, 1, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "features.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH5wlL2xSMPR"
      },
      "source": [
        "### Bag of Words (BoW) Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WFGc7lDSMPR"
      },
      "source": [
        "The weight in the vector of a given document expresses the number of occurrences of the given feature/term from vocabulary in the list of features/terms of the given document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGpkMybYSMPR",
        "outputId": "448d1734-e5f4-4604-e661-b4574d784fb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'long', 'movie', 'scary', 'slow', 'spooky']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "bow = CountVectorizer()\n",
        "features = bow.fit_transform(preprocessed_rewiews)\n",
        "\n",
        "# print vocabulary\n",
        "bow.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34RG0dGtSMPR"
      },
      "source": [
        "Occurrences of features/terms from vocabulary in the list of features/terms of the given document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgaGCL0USMPR",
        "outputId": "5a5baeb5-be4f-41e4-b4f4-276d1ce09ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 0, 'long': 1, 'movie': 1, 'scary': 1, 'slow': 0, 'spooky': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 0, 'long': 0, 'movie': 1, 'scary': 1, 'slow': 1, 'spooky': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 2, 'long': 0, 'movie': 1, 'scary': 0, 'slow': 0, 'spooky': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "dict(zip(bow.get_feature_names(), features.toarray()[0]))\n",
        "dict(zip(bow.get_feature_names(), features.toarray()[1]))\n",
        "dict(zip(bow.get_feature_names(), features.toarray()[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v92y6Y6GSMPS"
      },
      "source": [
        "Structured vector representation of three documents in the feature matrix. This matrix can already be folded as in the input to DM/ MLalgorithms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvyWsM3CSMPS",
        "outputId": "703e0d4c-261d-4d0f-d90a-410093e19390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0],\n",
              "       [0, 0, 1, 1, 1, 0],\n",
              "       [2, 0, 1, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "features.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL5B6JNSSMPS"
      },
      "source": [
        "###  Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "Unlike the BoW model, it represents a more sophisticated approach to creating vector representations of lists of features/terms of the original documents.\n",
        "\n",
        "The weight in the vector of a given document expresses the weight of individual feature/term from vocabulary in the document, in the context of all documents.\n",
        "\n",
        "During the calculation of the vector weights of a given document, this approach does not take into account only the given document (individual list of features/terms), but takes into account the entire document base (all lists of features/terms).\n",
        "\n",
        "Approach intuition:\n",
        "- if the given feature/term occurs in the given document, but also in all others, then the weight of the given feature/term will be negligible in the given document\n",
        "- if the given feature/term occurs in the given document and in no other, then the weight of the given feature/term will be significant in the given document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN3cdnVFSMPT",
        "outputId": "2609c994-4215-468a-8e35-6105d655c458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'long', 'movie', 'scary', 'slow', 'spooky']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "features = tfidf.fit_transform(preprocessed_rewiews)\n",
        "\n",
        "# print vocabulary\n",
        "tfidf.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw8JZx5TSMPT"
      },
      "source": [
        "Occurrences of features/terms from vocabulary in the list of features/terms of the given document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzovHqcxSMPT",
        "outputId": "a3c233a1-be51-4a70-c490-f63de66bdc84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 0.0,\n",
              " 'long': 0.7203334490549893,\n",
              " 'movie': 0.4254405389711991,\n",
              " 'scary': 0.5478321549274363,\n",
              " 'slow': 0.0,\n",
              " 'spooky': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 0.0,\n",
              " 'long': 0.0,\n",
              " 'movie': 0.4254405389711991,\n",
              " 'scary': 0.5478321549274363,\n",
              " 'slow': 0.7203334490549893,\n",
              " 'spooky': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 0.864770177579381,\n",
              " 'long': 0.0,\n",
              " 'movie': 0.25537359879528915,\n",
              " 'scary': 0.0,\n",
              " 'slow': 0.0,\n",
              " 'spooky': 0.4323850887896905}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "dict(zip(tfidf.get_feature_names(), features.toarray()[0]))\n",
        "dict(zip(tfidf.get_feature_names(), features.toarray()[1]))\n",
        "dict(zip(tfidf.get_feature_names(), features.toarray()[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVq7HXKWSMPT"
      },
      "source": [
        "Structured vector representation of three documents in the feature matrix. This matrix can already be folded as in the input to DM/ ML algorithms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cXEdApY6SMPU",
        "outputId": "6c4668f4-a62e-4e36-c666-0cb00a7e54f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.72033345, 0.42544054, 0.54783215, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.42544054, 0.54783215, 0.72033345,\n",
              "        0.        ],\n",
              "       [0.86477018, 0.        , 0.2553736 , 0.        , 0.        ,\n",
              "        0.43238509]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "features.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZQ1eV1cSMPU"
      },
      "source": [
        "### BERT\n",
        "\n",
        "For the purpose of feature extraction, we will now use the pre-trained BERT model. It works as a transformer encoder, performing both word and sentence / document embedding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QugZ_IXooaQW",
        "outputId": "dc12b876-521d-432b-cd7d-3dd74b431ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svik3ceuSMPU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPrSPzQ0SMPU"
      },
      "source": [
        "Import of BERT model including tool for tokenization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwirWRjtSMPU",
        "outputId": "75f46c8f-6064-462f-bc3f-43f04c9d43f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZywvhjqSMPV"
      },
      "source": [
        "We will now tokenize the preprocessed text. It consists in dividing individual texts into tokens, which are then replaced by their identifiers. Finally, the first [CSL] and last [SEP] token is added in the context of each text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqDXt1UkSMPV",
        "outputId": "e46100a1-ae7c-42f6-e8cc-657134d91b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[101, 3185, 12459, 2146, 102],\n",
              " [101, 3185, 12459, 4030, 102],\n",
              " [101, 3185, 11867, 14659, 2100, 2204, 2204, 102]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "tokenized_texts = [tokenizer.encode(x, add_special_tokens=True) for x in preprocessed_rewiews]\n",
        "tokenized_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWDcjXmVSMPV"
      },
      "source": [
        "The result is a list of lists, where one list (a list of token identifiers of a given text) represents exactly one document. We are now transforming this output into a matrix form:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkCcZ7XWSMPV",
        "outputId": "9e922c08-e47e-422c-b027-ec194586deae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101,  3185, 12459,  2146,   102,     0,     0,     0],\n",
              "       [  101,  3185, 12459,  4030,   102,     0,     0,     0],\n",
              "       [  101,  3185, 11867, 14659,  2100,  2204,  2204,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "max_len = 0\n",
        "for i in tokenized_texts:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "tokenized_texts_matrix = np.array([i + [0]*(max_len-len(i)) for i in tokenized_texts])\n",
        "np.array(tokenized_texts_matrix).shape\n",
        "tokenized_texts_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_IEHbjGSMPV"
      },
      "source": [
        "Then we create an auxiliary matrix. This instructs the BERT model to ignore the artificial fill we created during the generation of the above matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VseD-903SMPV",
        "outputId": "2edbf45d-dd4d-4fe8-981a-4a65c4737ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "attention_mask_matrix = np.where(tokenized_texts_matrix != 0, 1, 0)\n",
        "attention_mask_matrix.shape\n",
        "attention_mask_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bJNrrSnSMPW"
      },
      "source": [
        "We now create an input tensor out of the padded token matrix, and send that to BERT:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK2Ck_tBSMPW",
        "outputId": "126298b3-82e6-4197-844e-096c41fc7d70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 8, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "input_ids = torch.tensor(tokenized_texts_matrix)  \n",
        "attention_mask = torch.tensor(attention_mask_matrix)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "last_hidden_states[0].numpy().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79-iFyb4SMPW"
      },
      "source": [
        "The results of the processing will be returned into last_hidden_states. It takes the form of 768 matrices with three rows (one for each document) and 7 columns (number of tokens in the longest document + added first and last token). Of the given output, we are mainly interested in the output corresponding to the first token [CLS]. It represents vector representations of given preprocessed texts.\n",
        "\n",
        "We obtain vector representations of the given texts by selecting the first column from all matrices. The vector representation of, for example, the first document then corresponds to a vector composed of values located in the first column and the first row across the 768 matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VvEMv_nSMPW",
        "outputId": "d5df8d03-7b97-4c8a-ac9d-0649af0b6a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()\n",
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiA3YsjtSMPW",
        "outputId": "7e06a3cf-1b08-41ec-c0c0-ea1269e145c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.140288 -0.087131 -0.054506 -0.019884 -0.065086 -0.246025  0.417704   \n",
              "1 -0.185637 -0.097629  0.030227  0.085130 -0.002963 -0.207856  0.342549   \n",
              "2 -0.116938  0.305265 -0.030803  0.046325 -0.075579 -0.485094  0.517049   \n",
              "\n",
              "        7         8         9    ...       758       759       760       761  \\\n",
              "0  0.253575 -0.464968  0.246298  ...  0.312790 -0.215165  0.134716 -0.120480   \n",
              "1  0.278062 -0.376936  0.175713  ...  0.241079 -0.187037  0.088140  0.022385   \n",
              "2  0.243507 -0.266563 -0.004577  ...  0.079356 -0.266142  0.145712  0.326372   \n",
              "\n",
              "        762       763       764       765       766       767  \n",
              "0  0.122271  0.041049  0.101864 -0.354337  0.330353  0.151576  \n",
              "1  0.105548 -0.016295  0.045817 -0.193568  0.346718  0.090901  \n",
              "2  0.162020  0.217919 -0.279785 -0.284029  0.281404  0.125248  \n",
              "\n",
              "[3 rows x 768 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0d96910-8d3e-4da8-ae84-5d0e74f6b294\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.140288</td>\n",
              "      <td>-0.087131</td>\n",
              "      <td>-0.054506</td>\n",
              "      <td>-0.019884</td>\n",
              "      <td>-0.065086</td>\n",
              "      <td>-0.246025</td>\n",
              "      <td>0.417704</td>\n",
              "      <td>0.253575</td>\n",
              "      <td>-0.464968</td>\n",
              "      <td>0.246298</td>\n",
              "      <td>...</td>\n",
              "      <td>0.312790</td>\n",
              "      <td>-0.215165</td>\n",
              "      <td>0.134716</td>\n",
              "      <td>-0.120480</td>\n",
              "      <td>0.122271</td>\n",
              "      <td>0.041049</td>\n",
              "      <td>0.101864</td>\n",
              "      <td>-0.354337</td>\n",
              "      <td>0.330353</td>\n",
              "      <td>0.151576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.185637</td>\n",
              "      <td>-0.097629</td>\n",
              "      <td>0.030227</td>\n",
              "      <td>0.085130</td>\n",
              "      <td>-0.002963</td>\n",
              "      <td>-0.207856</td>\n",
              "      <td>0.342549</td>\n",
              "      <td>0.278062</td>\n",
              "      <td>-0.376936</td>\n",
              "      <td>0.175713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.241079</td>\n",
              "      <td>-0.187037</td>\n",
              "      <td>0.088140</td>\n",
              "      <td>0.022385</td>\n",
              "      <td>0.105548</td>\n",
              "      <td>-0.016295</td>\n",
              "      <td>0.045817</td>\n",
              "      <td>-0.193568</td>\n",
              "      <td>0.346718</td>\n",
              "      <td>0.090901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.116938</td>\n",
              "      <td>0.305265</td>\n",
              "      <td>-0.030803</td>\n",
              "      <td>0.046325</td>\n",
              "      <td>-0.075579</td>\n",
              "      <td>-0.485094</td>\n",
              "      <td>0.517049</td>\n",
              "      <td>0.243507</td>\n",
              "      <td>-0.266563</td>\n",
              "      <td>-0.004577</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079356</td>\n",
              "      <td>-0.266142</td>\n",
              "      <td>0.145712</td>\n",
              "      <td>0.326372</td>\n",
              "      <td>0.162020</td>\n",
              "      <td>0.217919</td>\n",
              "      <td>-0.279785</td>\n",
              "      <td>-0.284029</td>\n",
              "      <td>0.281404</td>\n",
              "      <td>0.125248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 768 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0d96910-8d3e-4da8-ae84-5d0e74f6b294')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0d96910-8d3e-4da8-ae84-5d0e74f6b294 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0d96910-8d3e-4da8-ae84-5d0e74f6b294');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "df = pd.DataFrame(features)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KayljgI0SMPX"
      },
      "source": [
        "## NLP use cases with Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMV2xAf8SMPX"
      },
      "source": [
        "We will now show the use of the Spacy library using examples based on the presentation on NLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpGlNqQHSMPa"
      },
      "source": [
        "### Language detection "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy_langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhU09k75phdh",
        "outputId": "d34e0be1-ea24-4b2c-a449-099947725e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy_langdetect in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: langdetect==1.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy_langdetect) (1.0.7)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from spacy_langdetect) (3.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect==1.0.7->spacy_langdetect) (1.15.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy_langdetect) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy_langdetect) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy_langdetect) (8.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->spacy_langdetect) (57.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy_langdetect) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy_langdetect) (21.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfCgjjLrSMPa",
        "outputId": "0d0fbb4a-5b80-4b41-9d06-0f6ca702fa2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tagger', 'parser', 'ner']\n",
            "['tagger', 'parser', 'ner', 'language_detector']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'language': 'en', 'score': 0.9999965292307103},\n",
              " {'language': 'cs', 'score': 0.9999973635809726},\n",
              " {'language': 'de', 'score': 0.9999964289791994},\n",
              " {'language': 'bg', 'score': 0.9999947633281014}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from spacy_langdetect import LanguageDetector\n",
        "from spacy.language import Language\n",
        "\n",
        "#Language.component(\"language_detector\", func=LanguageDetector())\n",
        "print(nlp.pipe_names)\n",
        "if \"language_detector\" not in nlp.pipe_names:\n",
        "    nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
        "#nlp.pipe_names\n",
        "#nlp.add_pipe('language_detector', last=True)\n",
        "print(nlp.pipe_names)\n",
        "\n",
        "texts = [\"My mom taught me to finish everything on my plate at dinner.\",\n",
        "          \"Cvičení určené na procvičení stavby slov a vět a na určování slovních druhů.\",\n",
        "          \"Tina ist neu in der Stadt und kennt sich noch nicht aus.\",\n",
        "          \"Расцветали яблони и груши.\"]\n",
        "\n",
        "docs = list(nlp.pipe(texts))\n",
        "\n",
        "[text._.language for text in docs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j17MadS9SMPX"
      },
      "source": [
        "### Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dMnKUbeSMPX"
      },
      "source": [
        "NER allows easily identify the key elements in a text, like of:\n",
        "\n",
        "- people,\n",
        "- places,\n",
        "- brands,\n",
        "- monetary values,\n",
        "- and more. \n",
        "\n",
        "Extracting the main entities in a text helps sort unstructured data and detect important information, which is crucial if you have to deal with large datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkQT0oqBSMPY"
      },
      "source": [
        "#### Example 1: NER form short text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ik57YEOSMPY",
        "outputId": "3249038d-3721-4de4-a16d-76705eb9414f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Apple\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is looking at buying \\n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    U.K.\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\\n</mark>\\n startup for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $1 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('London', 'GPE')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Is always good to eat apple in \\n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    London\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\\n</mark>\\n.</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# define text document\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# identify and display NEs\n",
        "[(ent.text, ent.label_) for ent in doc.ents]\n",
        "    \n",
        "displacy.render(doc, style=\"ent\")\n",
        "\n",
        "text = \"Is always good to eat apple in London.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# identify and display NEs\n",
        "[(ent.text, ent.label_) for ent in doc.ents]\n",
        "    \n",
        "displacy.render(doc, style=\"ent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3l0vlHDSMPY"
      },
      "source": [
        "From the above output, it is clear that in the given document, three named entities are identified and classified:\n",
        "\n",
        "- Apple (organization)\n",
        "- U.K. (country)\n",
        "- $1 billion (money)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNmTcGbdSMPY"
      },
      "source": [
        "#### Example 2: NER from newspaper article"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1o9WYZ-SMPY"
      },
      "source": [
        "Suppose we want to find out which entities are most mentioned in the article *F.B.I. Agent Peter Strzok, Who Criticized Trump in Texts, Is Fired* published on August 13, 2018 in The New York Times (https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news).\n",
        "\n",
        "In the first step, based on the url of the web page using the get method (HTTP method), we obtain an html file containing the analyzed article. Then we extract the text of the article from the html file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1ranjk3SMPY"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "\n",
        "def url_to_string(url):\n",
        "    # get html\n",
        "    res = requests.get(url)\n",
        "    html = res.text\n",
        "    \n",
        "    # extract relevant text from html\n",
        "    soup = BeautifulSoup(html, 'html5lib')\n",
        "    [script.extract() for script in soup([\"script\", \"style\", 'aside'])]\n",
        "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))\n",
        "\n",
        "# get atricle and it's text\n",
        "ny_bb = url_to_string('https://www.theguardian.com/us-news/2018/aug/13/fbi-fires-peter-strzok-agent-who-criticized-trump-in-text-messages')\n",
        "article = nlp(ny_bb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ny_bb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "tBF43KeBrTap",
        "outputId": "3b6cd05b-d8c7-4605-a961-291d78a93566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"                      Peter Strzok: FBI fires agent who criticized Trump in text messages | FBI | The Guardian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Skip to main contentSkip to navigationAdvertisementUS editionUS editionUK editionAustralian editionInternational editionThe Guardian - Back to homeThe Guardian: news website of the yearSearch jobs Sign inSearchNewsOpinionSportCultureLifestyleShowMoreShow MoreNewsUS newsWorld newsEnvironmentSoccerUS politicsBusinessTechScienceNewslettersFight to voteOpinionThe Guardian viewColumnistsLettersOpinion videosCartoonsSportSoccerNFLTennisMLBMLSNBANHLF1CultureFilmBooksMusicArt & designTV & radioStageClassicalGamesLifestyleFashionFoodRecipesLove & sexHome & gardenHealth & fitnessFamilyTravelMoneyMake a contributionSubscribeSearch jobsDigital ArchiveGuardian Puzzles appGuardian content licensing siteThe Guardian appVideoPodcastsPicturesInside the GuardianGuardian WeeklyCrosswordsFacebookTwitterSearch jobsDigital ArchiveGuardian Puzzles appGuardian content licensing site This article is more than 3 years oldPeter Strzok: FBI fires agent who criticized Trump in text messagesThis article is more than 3 years oldDismissal of agent who helped oversee investigations into Russian election meddling and Clinton’s emails ‘deeply troubling’ – lawyer Peter Strzok was a 21-year veteran of the FBI. Photograph: Evan Vucci/APPeter Strzok was a 21-year veteran of the FBI. Photograph: Evan Vucci/APFBI agent Peter Strzok, who once helped lead the bureau’s investigation into Russian election interference and sent texts disparaging Donald Trump, has been fired by the bureau.FBI agent rejects allegations of anti-Trump bias as a 'notch in Putin's belt'Read moreStrzok, a 21-year veteran of the organisation, helped oversee both the Russia inquiry and the investigation of Hillary Clinton’s emails, but sent texts critical of Trump including one where he labeled the future president an “idiot”.An inspector general’s report in June revealed a history of text messages sent during the 2016 presidential between Strzok and Lisa Page, then an FBI lawyer with whom he was having an affair.In one exchange, Page asked: “[Trump’s] not ever going to become president, right? Right?!” Strzok replied: “No. No he’s not. We’ll stop it.”The inspector general’s office found no evidence that the attitudes reflected in the texts affected investigatory work, but said the pair’s text messages “cast a cloud” over the investigation into Clinton’s use of a private email server while she was secretary of state.Trump and his allies have blasted Strzok, making him a poster boy for their claim that the investigation into Russian interference in the 2016 election is a “witch-hunt”.Special counsel Robert Mueller removed Strzok from the Russia investigation after the messages were discovered.Strzok’s lawyer said FBI deputy director David Bowdich ordered the firing on Friday – overruling the bureau’s office of professional responsibility and going against the recommendation of the career FBI official responsible for employee discipline, who had said Strzok should be suspended for 60 days and stripped of his supervisory responsibilities.“This decision [to fire Strzok] should be deeply troubling to all Americans,” Strzok’s lawyer, Aitan Goelman, said in a statement.“A lengthy investigation and multiple rounds of congressional testimony failed to produce a shred of evidence that Special Agent Strzok’s personal views ever affected his work,” he said. “The decision to terminate was taken in response to political pressure, and to punish Special Agent Strzok for political speech protected by the first amendment, not on a fair and independent examination of the facts.”Trump exulted over the firing on Monday.“Agent Peter Strzok was just fired from the FBI – finally. The list of bad players in the FBI & DOJ gets longer & longer. Based on the fact that Strzok was in charge of the Witch Hunt, will it be dropped? It is a total Hoax. No Collusion, No Obstruction – I just fight back!” he said on Twitter.Just fired Agent Strzok, formerly of the FBI, was in charge of the Crooked Hillary Clinton sham investigation. It was a total fraud on the American public and should be properly redone!— Donald J. Trump (@realDonaldTrump) August 13, 2018 Trump added in another tweet: “Just fired Agent Strzok, formerly of the FBI, was in charge of the Crooked Hillary Clinton sham investigation. It was a total fraud on the American public and should be properly redone!”Testifying before House committees last month, Strzok said his personal views had never affected his work and called Republican attacks against him “another victory notch in Putin’s belt”.TopicsFBITrump-Russia investigationDonald TrumpnewsReuse this contentNewsOpinionSportCultureLifestyleAll the day's headlines and highlights from the Guardian, direct to you every morningSign up for our emailAbout usContact usComplaints & correctionsSecureDropWork for usPrivacy policyCookie policyTerms & conditionsHelpAll topicsAll writersDigital newspaper archiveFacebookYouTubeInstagramLinkedInTwitterNewslettersAdvertise with usGuardian LabsSearch jobsBack to top© 2022 Guardian News & Media Limited or its affiliated companies. All rights reserved. (modern)                                       \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDarSNZHSMPZ"
      },
      "source": [
        "We will now display:\n",
        "- total number of recognized NEs\n",
        "- number of NEs by individual categories\n",
        "- most common/most frequent NEs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkjPYYYySMPZ",
        "outputId": "d2a10e7e-3531-450a-81d5-a952ce5b409a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'CARDINAL': 2,\n",
              "         'DATE': 11,\n",
              "         'GPE': 2,\n",
              "         'NORP': 11,\n",
              "         'ORDINAL': 1,\n",
              "         'ORG': 34,\n",
              "         'PERSON': 33,\n",
              "         'PRODUCT': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Strzok', 16),\n",
              " ('FBI', 12),\n",
              " ('Trump', 5),\n",
              " ('Peter Strzok', 4),\n",
              " ('Russian', 3),\n",
              " ('ArchiveGuardian', 2),\n",
              " ('appGuardian', 2),\n",
              " ('more than 3 years', 2),\n",
              " ('Clinton', 2),\n",
              " ('Evan Vucci', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# total number of recognized NEs\n",
        "len(article.ents)\n",
        "\n",
        "# number of NEs by individual categories\n",
        "Counter([ent.label_ for ent in article.ents])\n",
        "\n",
        "# most common/most frequent NEs\n",
        "Counter([ent.text for ent in article.ents]).most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1SAN8OQSMPZ"
      },
      "source": [
        "From the above overview, it is clear that the article informs about certain issues that are, among other things, associated with:\n",
        "- Strzok,\n",
        "- F.B.I.,\n",
        "- Trump,\n",
        "- Russia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5LiM4WOSMPZ"
      },
      "source": [
        "Finally, we display a random sentence from the article, including the named entities contained in it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJEU024ZSMPZ",
        "outputId": "361a07e0-d7c5-42cc-d5a0-790ef1705324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">                      \\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Peter Strzok\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\\n</mark>\\n: \\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    FBI\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n fires agent who criticized \\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Trump\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n in text messages </div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "sentences = [sen for sen in article.sents]\n",
        "\n",
        "displacy.render(sentences[0], style=\"ent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv7gmvrFSMPa"
      },
      "source": [
        "### Summarization\n",
        "\n",
        "Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while at the same time preserving key informational elements and the meaning of content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHTEcdP3SMPa"
      },
      "source": [
        "#### Extractive Text Summarization with spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCOxYhsiSMPb"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "from heapq import nlargest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmDPvWeESMPb"
      },
      "source": [
        "The purpose of the following procedure is to call up a summary that will consist of the most important sentences of the original text. The importance of a sentence is expressed by the sum of the weights of the keywords that occur in the given sentence. In other words, the sentence is important depending on the importance of the keywords it contains.\n",
        "\n",
        "We first identify the keywords in the text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmVW59K8SMPb",
        "outputId": "105480be-4545-44a0-a8f2-018b0a2a2206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "429"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Peter',\n",
              " 'Strzok',\n",
              " 'FBI',\n",
              " 'fires',\n",
              " 'agent',\n",
              " 'criticized',\n",
              " 'Trump',\n",
              " 'text',\n",
              " 'messages',\n",
              " '|']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
        "keyword = [token.text for token in article \n",
        "           if not token.is_punct | token.is_space | token.is_stop == True \n",
        "           if token.pos_ in pos_tag]\n",
        "\n",
        "len(keyword)\n",
        "keyword[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYKM-nZSSMPb"
      },
      "source": [
        "The analyzed text contains 770 keywords.\n",
        "\n",
        "We will now calculate the frequency of occurrence of individual keywords in the text. Then we will display the 5 most frequented of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0dlxI-ISMPb",
        "outputId": "2874c9ea-f819-4b85-d2b7-7eac10de6fe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Strzok', 20),\n",
              " ('FBI', 13),\n",
              " ('Trump', 9),\n",
              " ('investigation', 8),\n",
              " ('Guardian', 7)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "freq_word = Counter(keyword)\n",
        "freq_word.most_common(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfnGXz_nSMPc"
      },
      "source": [
        "We are now normalizing these frequencies for better processing. This is accomplished by dividing the frequency of each keyword by the maximum frequency. We get the weights of individual keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d91Wfw6-SMPc",
        "outputId": "cf46f17f-01b7-479e-8c10-7572442c49be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Strzok', 1.0),\n",
              " ('FBI', 0.65),\n",
              " ('Trump', 0.45),\n",
              " ('investigation', 0.4),\n",
              " ('Guardian', 0.35)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "max_freq = Counter(keyword).most_common(1)[0][1]\n",
        "max_freq\n",
        "\n",
        "for word in freq_word.keys():  \n",
        "        freq_word[word] = (freq_word[word]/max_freq)\n",
        "\n",
        "freq_word.most_common(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNEDHCEbSMPc"
      },
      "source": [
        "In this main part of the whole process, we determine the weights of the individual sentences of the text. The weight of a sentence is determined by the weights of individual keywords that occur in the given sentence. Sentence weight expresses the sum of the weights of individual keywords that occur in a sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oza39gmSMPc",
        "outputId": "4a433131-17af-4b6d-d6ab-5ffa25af6aca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.150000000000001, 0.85, 0.35, 0.25, 0.05]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "sent_strength={}\n",
        "for sent in article.sents:\n",
        "    for word in sent:\n",
        "        if word.text in freq_word.keys(): # is word a keyword?\n",
        "            if sent in sent_strength.keys():\n",
        "                sent_strength[sent]+=freq_word[word.text]\n",
        "            else:\n",
        "                sent_strength[sent]=freq_word[word.text]\n",
        "                \n",
        "list(sent_strength.values())[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlZtMWulSMPc"
      },
      "source": [
        "Finally, nlargest function is used to summarize the string. The nlargest function returns a list containing the top 3 sentences which are stored as *summarized_sentences*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfjxCZWSSMPd"
      },
      "outputs": [],
      "source": [
        "summarized_sentences = nlargest(3, sent_strength, key=sent_strength.get)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8Ge4WV3SMPd"
      },
      "source": [
        "This can be converted to a string by the following lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfrAmgAeSMPd",
        "outputId": "0a6defd8-7439-452d-d539-a612d8509406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Strzok’s lawyer said FBI deputy director David Bowdich ordered the firing on Friday – overruling the bureau’s office of professional responsibility and going against the recommendation of the career FBI official responsible for employee discipline, who had said Strzok should be suspended for 60 days and stripped of his supervisory responsibilities.\\nFBI agent rejects allegations of anti-Trump bias as a 'notch in Putin's belt'Read moreStrzok, a 21-year veteran of the organisation, helped oversee both the Russia inquiry and the investigation of Hillary Clinton’s emails, but sent texts critical of Trump including one where he labeled the future president an “idiot”.\\nEvan Vucci/APFBI agent Peter Strzok, who once helped lead the bureau’s investigation into Russian election interference and sent texts disparaging Donald Trump, has been fired by the bureau.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "final_sentences = [w.text for w in summarized_sentences]\n",
        "summary = '\\n'.join(final_sentences)\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxvGLCkNSMPh"
      },
      "source": [
        "#### Extractive Text Summarization with Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45892SxWSMPh",
        "outputId": "5f7758bf-9141-49dd-f31c-3cbd23d40833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Photograph: Evan Vucci/APFBI agent Peter Strzok, who once helped lead the bureau’s investigation into Russian election interference and sent texts disparaging Donald Trump, has been fired by the bureau.FBI agent rejects allegations of anti-Trump bias as a 'notch in Putin's belt'Read moreStrzok, a 21-year veteran of the organisation, helped oversee both the Russia inquiry and the investigation of Hillary Clinton’s emails, but sent texts critical of Trump including one where he labeled the future president an “idiot”.An inspector general’s report in June revealed a history of text messages sent during the 2016 presidential between Strzok and Lisa Page, then an FBI lawyer with whom he was having an affair.In one exchange, Page asked: “[Trump’s] not ever going to become president, right?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.summarization import summarize\n",
        "\n",
        "extractive_summary = summarize(ny_bb, word_count=100)\n",
        "extractive_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teQ7dIb0SMPd"
      },
      "source": [
        "### Word/Document vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnO6nuUySMPd"
      },
      "source": [
        "The spaCy library allows you to convert words and entire documents into their vector representation. The library uses the trained Word2Vec static embedding model, which was trained on an extensive corpus. \n",
        "\n",
        "The created vector representations can be used, for example, to compare words or documents with each other.\n",
        "\n",
        "#### Word vectors and similarity\n",
        "\n",
        "Each existing token has a relationship to the trained model of word vectors, which can be characterized by three attributes:\n",
        "\n",
        "- *has_vector*, if the token has a vector,\n",
        "- *vector_norm*, L2 norm of the token’s vector (the square root of the sum of the values squared),\n",
        "- *OOV*, Out-of-vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb7Z1PGESMPe",
        "outputId": "016f977f-ce9e-48ae-e5cb-59de034b91b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           has_vector  vector_norm is_oov\n",
              "I                True     6.423194  False\n",
              "like             True     4.783220  False\n",
              "salty            True     6.918513  False\n",
              "fries            True     7.299067  False\n",
              "and              True     4.657798  False\n",
              "hamburgers       True     7.088755  False\n",
              ".                True     4.931635  False"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5c88aaf-a859-4398-9006-6f2b1e4f377d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>has_vector</th>\n",
              "      <th>vector_norm</th>\n",
              "      <th>is_oov</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>I</th>\n",
              "      <td>True</td>\n",
              "      <td>6.423194</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>True</td>\n",
              "      <td>4.783220</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>salty</th>\n",
              "      <td>True</td>\n",
              "      <td>6.918513</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fries</th>\n",
              "      <td>True</td>\n",
              "      <td>7.299067</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>True</td>\n",
              "      <td>4.657798</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hamburgers</th>\n",
              "      <td>True</td>\n",
              "      <td>7.088755</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>True</td>\n",
              "      <td>4.931635</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5c88aaf-a859-4398-9006-6f2b1e4f377d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5c88aaf-a859-4398-9006-6f2b1e4f377d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5c88aaf-a859-4398-9006-6f2b1e4f377d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "doc = nlp(\"I like salty fries and hamburgers.\")\n",
        "\n",
        "vectors = pd.DataFrame()\n",
        "\n",
        "for token in doc:\n",
        "    vectors.loc[token,\"has_vector\"] = token.has_vector\n",
        "    vectors.loc[token,\"vector_norm\"] = token.vector_norm\n",
        "    vectors.loc[token,\"is_oov\"] = token.is_oov    \n",
        "vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V05JNZIHSMPe"
      },
      "source": [
        "If we have vectors of individual tokens, then we can proceed to compare these vectors. \n",
        "\n",
        "The *similarity* function is used to calculate the similarity of two vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtVkEn7tSMPe",
        "outputId": "e3a73899-9ae3-4232-e7b9-f1f203083eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f3eff28cf50>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_48bad_row0_col0, #T_48bad_row1_col1, #T_48bad_row2_col2, #T_48bad_row3_col3, #T_48bad_row4_col4, #T_48bad_row5_col5, #T_48bad_row6_col6 {\n",
              "  background-color: #00441b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_48bad_row0_col1 {\n",
              "  background-color: #97d7c7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row0_col2 {\n",
              "  background-color: #e5f5f9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row0_col3 {\n",
              "  background-color: #eff9fb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row0_col4 {\n",
              "  background-color: #dcf2f2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row0_col5 {\n",
              "  background-color: #eaf7fa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row0_col6, #T_48bad_row6_col4 {\n",
              "  background-color: #b4e2d8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row1_col0 {\n",
              "  background-color: #78cab1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row1_col2 {\n",
              "  background-color: #d2eeeb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row1_col3 {\n",
              "  background-color: #e3f4f7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row1_col4 {\n",
              "  background-color: #84cfb9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row1_col5 {\n",
              "  background-color: #d1eee9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row1_col6 {\n",
              "  background-color: #b0e1d6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row2_col0 {\n",
              "  background-color: #f1fafc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row2_col1, #T_48bad_row4_col3 {\n",
              "  background-color: #f3fafc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row2_col3 {\n",
              "  background-color: #80cdb7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row2_col4, #T_48bad_row4_col5 {\n",
              "  background-color: #ebf7fa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row2_col5 {\n",
              "  background-color: #98d8c9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row2_col6, #T_48bad_row3_col1, #T_48bad_row5_col0, #T_48bad_row5_col4, #T_48bad_row5_col6, #T_48bad_row6_col2, #T_48bad_row6_col3, #T_48bad_row6_col5 {\n",
              "  background-color: #f7fcfd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row3_col0, #T_48bad_row5_col1 {\n",
              "  background-color: #f2fafc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row3_col2 {\n",
              "  background-color: #70c6ac;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row3_col4 {\n",
              "  background-color: #f5fbfc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row3_col5 {\n",
              "  background-color: #127c39;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_48bad_row3_col6 {\n",
              "  background-color: #edf8fb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row4_col0, #T_48bad_row4_col2 {\n",
              "  background-color: #ddf2f3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row4_col1 {\n",
              "  background-color: #a7ddd1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row4_col6 {\n",
              "  background-color: #9cd9ca;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row5_col2 {\n",
              "  background-color: #9ad8ca;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row5_col3 {\n",
              "  background-color: #16803c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_48bad_row6_col0 {\n",
              "  background-color: #ceede8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_48bad_row6_col1 {\n",
              "  background-color: #e1f4f6;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_48bad_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >I</th>\n",
              "      <th class=\"col_heading level0 col1\" >like</th>\n",
              "      <th class=\"col_heading level0 col2\" >salty</th>\n",
              "      <th class=\"col_heading level0 col3\" >fries</th>\n",
              "      <th class=\"col_heading level0 col4\" >and</th>\n",
              "      <th class=\"col_heading level0 col5\" >hamburgers</th>\n",
              "      <th class=\"col_heading level0 col6\" >.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_48bad_level0_row0\" class=\"row_heading level0 row0\" >I</th>\n",
              "      <td id=\"T_48bad_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
              "      <td id=\"T_48bad_row0_col1\" class=\"data row0 col1\" >0.555491</td>\n",
              "      <td id=\"T_48bad_row0_col2\" class=\"data row0 col2\" >0.214086</td>\n",
              "      <td id=\"T_48bad_row0_col3\" class=\"data row0 col3\" >0.212421</td>\n",
              "      <td id=\"T_48bad_row0_col4\" class=\"data row0 col4\" >0.316079</td>\n",
              "      <td id=\"T_48bad_row0_col5\" class=\"data row0 col5\" >0.181652</td>\n",
              "      <td id=\"T_48bad_row0_col6\" class=\"data row0 col6\" >0.377928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_48bad_level0_row1\" class=\"row_heading level0 row1\" >like</th>\n",
              "      <td id=\"T_48bad_row1_col0\" class=\"data row1 col0\" >0.555491</td>\n",
              "      <td id=\"T_48bad_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
              "      <td id=\"T_48bad_row1_col2\" class=\"data row1 col2\" >0.300753</td>\n",
              "      <td id=\"T_48bad_row1_col3\" class=\"data row1 col3\" >0.280542</td>\n",
              "      <td id=\"T_48bad_row1_col4\" class=\"data row1 col4\" >0.526748</td>\n",
              "      <td id=\"T_48bad_row1_col5\" class=\"data row1 col5\" >0.306152</td>\n",
              "      <td id=\"T_48bad_row1_col6\" class=\"data row1 col6\" >0.387020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_48bad_level0_row2\" class=\"row_heading level0 row2\" >salty</th>\n",
              "      <td id=\"T_48bad_row2_col0\" class=\"data row2 col0\" >0.214086</td>\n",
              "      <td id=\"T_48bad_row2_col1\" class=\"data row2 col1\" >0.300753</td>\n",
              "      <td id=\"T_48bad_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
              "      <td id=\"T_48bad_row2_col3\" class=\"data row2 col3\" >0.527844</td>\n",
              "      <td id=\"T_48bad_row2_col4\" class=\"data row2 col4\" >0.249443</td>\n",
              "      <td id=\"T_48bad_row2_col5\" class=\"data row2 col5\" >0.437844</td>\n",
              "      <td id=\"T_48bad_row2_col6\" class=\"data row2 col6\" >0.100576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_48bad_level0_row3\" class=\"row_heading level0 row3\" >fries</th>\n",
              "      <td id=\"T_48bad_row3_col0\" class=\"data row3 col0\" >0.212421</td>\n",
              "      <td id=\"T_48bad_row3_col1\" class=\"data row3 col1\" >0.280542</td>\n",
              "      <td id=\"T_48bad_row3_col2\" class=\"data row3 col2\" >0.527844</td>\n",
              "      <td id=\"T_48bad_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "      <td id=\"T_48bad_row3_col4\" class=\"data row3 col4\" >0.190629</td>\n",
              "      <td id=\"T_48bad_row3_col5\" class=\"data row3 col5\" >0.828722</td>\n",
              "      <td id=\"T_48bad_row3_col6\" class=\"data row3 col6\" >0.165359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_48bad_level0_row4\" class=\"row_heading level0 row4\" >and</th>\n",
              "      <td id=\"T_48bad_row4_col0\" class=\"data row4 col0\" >0.316079</td>\n",
              "      <td id=\"T_48bad_row4_col1\" class=\"data row4 col1\" >0.526748</td>\n",
              "      <td id=\"T_48bad_row4_col2\" class=\"data row4 col2\" >0.249443</td>\n",
              "      <td id=\"T_48bad_row4_col3\" class=\"data row4 col3\" >0.190629</td>\n",
              "      <td id=\"T_48bad_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
              "      <td id=\"T_48bad_row4_col5\" class=\"data row4 col5\" >0.175625</td>\n",
              "      <td id=\"T_48bad_row4_col6\" class=\"data row4 col6\" >0.432417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_48bad_level0_row5\" class=\"row_heading level0 row5\" >hamburgers</th>\n",
              "      <td id=\"T_48bad_row5_col0\" class=\"data row5 col0\" >0.181652</td>\n",
              "      <td id=\"T_48bad_row5_col1\" class=\"data row5 col1\" >0.306152</td>\n",
              "      <td id=\"T_48bad_row5_col2\" class=\"data row5 col2\" >0.437844</td>\n",
              "      <td id=\"T_48bad_row5_col3\" class=\"data row5 col3\" >0.828722</td>\n",
              "      <td id=\"T_48bad_row5_col4\" class=\"data row5 col4\" >0.175625</td>\n",
              "      <td id=\"T_48bad_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
              "      <td id=\"T_48bad_row5_col6\" class=\"data row5 col6\" >0.099524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_48bad_level0_row6\" class=\"row_heading level0 row6\" >.</th>\n",
              "      <td id=\"T_48bad_row6_col0\" class=\"data row6 col0\" >0.377928</td>\n",
              "      <td id=\"T_48bad_row6_col1\" class=\"data row6 col1\" >0.387020</td>\n",
              "      <td id=\"T_48bad_row6_col2\" class=\"data row6 col2\" >0.100576</td>\n",
              "      <td id=\"T_48bad_row6_col3\" class=\"data row6 col3\" >0.165359</td>\n",
              "      <td id=\"T_48bad_row6_col4\" class=\"data row6 col4\" >0.432417</td>\n",
              "      <td id=\"T_48bad_row6_col5\" class=\"data row6 col5\" >0.099524</td>\n",
              "      <td id=\"T_48bad_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "similarity_map = pd.DataFrame(columns=doc)\n",
        "\n",
        "for token in doc:\n",
        "    for token2 in doc:\n",
        "        similarity_map.loc[token, token2] = token.similarity(token2)\n",
        "\n",
        "similarity_map.apply(pd.to_numeric).style.background_gradient(cmap ='BuGn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d31YBsHSMPe"
      },
      "source": [
        "#### Document vectors and similarity\n",
        "\n",
        "As with words, you can measure the similarity of entire documents by calling the *similarity* function. The similarity of documents is measured using document vectors, the calculation of which also includes the vectors of individual words.\n",
        "\n",
        "In the following example, we compare a query with two documents, in other words, we calculate the similarity between the query vector and the vectors of both documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIDnITwxSMPf",
        "outputId": "1611943e-34d5-48cb-bf71-7d8b3b67e801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f3ddac89f90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_df0e2_row0_col0 {\n",
              "  background-color: #f5fbfc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_df0e2_row1_col0 {\n",
              "  background-color: #f7fcfd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_df0e2_row2_col0 {\n",
              "  background-color: #e6f5f9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_df0e2_row3_col0 {\n",
              "  background-color: #f0f9fb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_df0e2_row4_col0 {\n",
              "  background-color: #00441b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_df0e2_row5_col0 {\n",
              "  background-color: #00451c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_df0e2_row6_col0 {\n",
              "  background-color: #39a569;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_df0e2_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >Fistfight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_df0e2_level0_row0\" class=\"row_heading level0 row0\" >This is my sample sentence</th>\n",
              "      <td id=\"T_df0e2_row0_col0\" class=\"data row0 col0\" >0.155412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_df0e2_level0_row1\" class=\"row_heading level0 row1\" >This car is beautiful</th>\n",
              "      <td id=\"T_df0e2_row1_col0\" class=\"data row1 col0\" >0.150065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_df0e2_level0_row2\" class=\"row_heading level0 row2\" >Movie was not very good</th>\n",
              "      <td id=\"T_df0e2_row2_col0\" class=\"data row2 col0\" >0.185105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_df0e2_level0_row3\" class=\"row_heading level0 row3\" >Driving around</th>\n",
              "      <td id=\"T_df0e2_row3_col0\" class=\"data row3 col0\" >0.164097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_df0e2_level0_row4\" class=\"row_heading level0 row4\" >Political fights</th>\n",
              "      <td id=\"T_df0e2_row4_col0\" class=\"data row4 col0\" >0.445665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_df0e2_level0_row5\" class=\"row_heading level0 row5\" >Boxing</th>\n",
              "      <td id=\"T_df0e2_row5_col0\" class=\"data row5 col0\" >0.443361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_df0e2_level0_row6\" class=\"row_heading level0 row6\" >MMA</th>\n",
              "      <td id=\"T_df0e2_row6_col0\" class=\"data row6 col0\" >0.344525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "texts = ['This is my sample sentence',\n",
        "         'This car is beautiful',\n",
        "        \"Movie was not very good\",\n",
        "        \"Driving around\",\n",
        "        \"Political fights\",\n",
        "        \"Boxing\",\n",
        "        \"MMA\"]\n",
        "query = \"Fistfight\" #'Beautiful car'\n",
        "\n",
        "docs = list(nlp.pipe(texts))\n",
        "doc_q = nlp(query)\n",
        "\n",
        "similarity_map = pd.DataFrame()\n",
        "\n",
        "for doc in docs:\n",
        "    similarity_map.loc[doc.text, doc_q.text] = doc_q.similarity(doc)\n",
        "        \n",
        "similarity_map.apply(pd.to_numeric).style.background_gradient(cmap ='BuGn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPn_-BAfSMPf",
        "outputId": "0121a3b1-cd3f-4dad-f4b0-c13f22419662",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "type(doc_q[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYU4CMXOSMPf"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ankkt3WSMPf"
      },
      "source": [
        "## NLP use cases with other libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhdH25ncSMPf"
      },
      "source": [
        "### Sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVf5BEpWSMPf"
      },
      "source": [
        "SA analyses an incoming text and tells whether the underlying sentiment is:\n",
        "- positive,\n",
        "- negative or\n",
        "- neutral. \n",
        "\n",
        "SA classifies texts according to the sentiment contained in them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsstKpMWSMPg"
      },
      "source": [
        "#### Rule-based/lexicon-based approach VADER "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGKWwvVISMPg"
      },
      "source": [
        "The VADER (Valence Aware Dictionary and sEntiment Reasoner) method represents a modified dictionary approach (rule-based/lexicon-based approaches) to sentiment analysis. VADER is specifically attuned to sentiments expressed in social media.\n",
        "\n",
        "Characteristics of the VADER method as rule-based/lexicon-based approach:\n",
        "\n",
        "- unlike approaches based on ML methods, VADER does not require any training data,\n",
        "- can very well understand the sentiment of a text containing emoticons, slangs, conjunctions, capital words, punctuations and much more,\n",
        "- works excellent on social media text,\n",
        "- can work with multiple domains.\n",
        "\n",
        "After importing the *SentimentIntensityAnalyzer* method from the vaderSentiment library, we will use the method in the context of four reviews to determine:\n",
        "- polarity score for each sentiment class,\n",
        "- summary compound value."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr-DoVPPqFF2",
        "outputId": "679095fc-d02c-45c3-8a2b-6ec9f3acdf41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2022.5.18.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lwgul12BSMPg",
        "outputId": "06ed7f16-e112-45c7-c79b-47ca441a3f21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"The food was great! But I didn't like the service.\",\n",
              "  {'compound': -0.1045, 'neg': 0.219, 'neu': 0.592, 'pos': 0.189}),\n",
              " ('I will definitely come again. Great menu.',\n",
              "  {'compound': 0.7783, 'neg': 0.0, 'neu': 0.424, 'pos': 0.576}),\n",
              " ('The atmosphere is nice and the service was helpful.',\n",
              "  {'compound': 0.6808, 'neg': 0.0, 'neu': 0.556, 'pos': 0.444}),\n",
              " (\"Not my style, I don't recommend it.\",\n",
              "  {'compound': -0.2755, 'neg': 0.26, 'neu': 0.74, 'pos': 0.0})]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
        "\n",
        "sentiment = SentimentIntensityAnalyzer()\n",
        "\n",
        "reviews = [\"The food was great! But I didn't like the service.\",\n",
        "          \"I will definitely come again. Great menu.\",\n",
        "          \"The atmosphere is nice and the service was helpful.\",\n",
        "          \"Not my style, I don't recommend it.\"]\n",
        "\n",
        "# print sentence and it's sentiment's scores\n",
        "[(r, sentiment.polarity_scores(r)) for r in reviews]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fyHxXjmSMPg"
      },
      "source": [
        "The calculated compound value can be used for classification purposes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t86btbQgSMPg",
        "outputId": "425027f2-a659-4392-ac08-692cfcc302ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"The food was great! But I didn't like the service.\", 'Negative'),\n",
              " ('I will definitely come again. Great menu.', 'Positive'),\n",
              " ('The atmosphere is nice and the service was helpful.', 'Positive'),\n",
              " (\"Not my style, I don't recommend it.\", 'Negative')]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# function for determining sentiment based on the compond value calculated by VADER\n",
        "def classify_sentiment(compound_value):\n",
        "    if compound_value >= 0.05 : \n",
        "            return(\"Positive\") \n",
        "\n",
        "    elif compound_value <= - 0.05 : \n",
        "            return(\"Negative\") \n",
        "\n",
        "    else : \n",
        "            return(\"Neutral\")\n",
        "        \n",
        "        \n",
        "[(r, classify_sentiment(sentiment.polarity_scores(r)['compound'])) for r in reviews]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "joGfXXA43dLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zcycRDfAeP6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "Copy of D4_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}